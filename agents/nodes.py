from core.llm_factory import get_llm
from core.models import ReflectionOutput, AgentState, UserIntent
from langchain_core.messages import HumanMessage
from langchain_core.messages import SystemMessage
import json
import re

llm = get_llm()

def strategist_node(state: AgentState):
    # Сохраняем твою логику, добавляя строгие технические ограничения
    system_prompt = f"""
        Представь, что ты наблюдаешь за техническим интервью. Интервьер - другая LLM модель.
        В следующих сообщениях ты будешь получать вопрос интервьера и ответа кандидата.
        Ты говоришь интервьюеру, что делать.

        В ОТВЕТАХ МОЖНО ИСПОЛЬЗОВАТЬ ТОЛЬКО РУССКИЙ ЯЗЫК.
        НЕ ИСПОЛЬЗУЙ НИКАКИЕ ДОПОЛНИТЕЛНЕНИЯ, В ТОМ ЧИСЛЕ MARKDOWN ТЕГИ И ```.
        
        ОТВЕЧАТЬ МОЖНО ТОЛЬКО В ВИДЕ JSON С ФИКСИРОВАННОЙ СТРУКТУРОЙ ПО ПРИМЕРУ:
        {{
        "intent": "string",
        "is_correct": boolean,
        "analysis": "оценка ответа",
        "strategy": "стратегия для интервьера про сложность вопросов (сложнее/легче, jun/middle/senior)",
        "instruction": "корректирующие инструкции для интервьера: сменить тему, объяснить правильный ответ и т.д.",
        "stop_interview": boolean
        }}

        ВСЕ ПОЛЯ В ПРИМЕРЕ ОБЯЗАТЕЛЬНЫ. 
        
        поле intent показывает намерение кандидата:
        1. greeting - приветствие
        2. answer - ответ на вопрос
        3. question - кандидат задал вопрос
        4. nonsense - бред/галлюцинация/троллинг
        5. command - клиент просит завершить интервью, дать фитбек
        6. i_dont_know - кандидат не знает ответа

        Общие рекомендации:
        - после приветствия стоит начать задавать технические вопросы
        - старайся варьировать сложность вопросов в зависимости от ответов кандидата
        - если кандидат говорит чушь или не знает ответ, используй intent=nonsense или intent=i_dont_know и дай правильный ответ
        - если кандидат задает вопросы, укажи intent=question и ответь на них (но только если вопросы по теме)
        - не давай менять тему и уходить от интервью
    """
    
    msgs = [SystemMessage(content=system_prompt)] + state["messages"]

    try:
        # Получаем сырой ответ для ручной очистки
        raw_res = llm.invoke(msgs)
        content = raw_res.content

        # Санитайзинг: удаляем ```json ... ``` и лишние символы
        clean_json = re.sub(r"```json\s?|```", "", content).strip()
        
        # Парсим в словарь
        data = json.loads(clean_json)
        
        # Валидируем через Pydantic
        res = ReflectionOutput(**data)
        
        # Формируем красивые internal_thoughts для интерфейса Chainlit
        thoughts = (
            f"**Intent:** {res.intent.value.upper()}\n"
            f"**Analysis:** {res.analysis}\n"
            f"**Strategy:** {res.strategy}\n"
            f"**Correct:** {'Да' if res.is_correct else 'Нет'}"
        )

    except Exception as e:
        # Если модель все же выдала битый JSON
        print(f"\n[DEBUG] Ошибка парсинга: {e}")
        return {
            "internal_thoughts": "⚠️ Ошибка структуры JSON. Переход в аварийный режим.",
            "next_instruction": "Продолжай диалог вежливо, уточни технические навыки кандидата.",
            "is_finished": False
        }
    
    return {
        "internal_thoughts": thoughts,
        "next_instruction": res.instruction,
        "is_finished": res.stop_interview or res.intent == UserIntent.COMMAND
    }

def interviewer_node(state: AgentState):

    is_first_message = len(state["messages"]) == 0
    
    
    prompt = f"""
    ТЫ: Профессиональный IT-рекрутер.
    ТВОЯ ЗАДАЧА: Вести техническое интервью, опираясь на указания Стратега.

    {"ЭТО НАЧАЛО ИНТЕРВЬЮ. Поприветствуй кандидата и расскажи, что он на техническом собеседовании. Попроси его представиться, тебе необходимо получить информацию о его позиции и навыках" if is_first_message else "Продолжай диалог согласно инструкции."}
    
    ИНСТРУКЦИЯ ОТ СТРАТЕГА(не говори это кандидату): {state['next_instruction']}
    
    ПРАВИЛА ОБЩЕНИЯ:
    1. Пиши ТОЛЬКО текст, предназначенный для кандидата.
    2. НИКОГДА не упоминай "Стратега", "Критика", "Инструкции" или "Баллы".
    3. Говори естественно, как человек. Используй только в подходящих случаях фразы: "Принято", "Хорошо, тогда пойдем дальше", "Интересно, а расскажи подробнее про...".
    4. Если Стратег говорит, что ответ неверный — не соглашайся с кандидатом. Вежливо поправь его или задай уточняющий вопрос, чтобы он сам нашел ошибку.
    5. Если инструкция требует задать вопрос — задавай его прямо.
    6. После получения ответа от кандидата — не подводи итоги и не делай выводы. Просто продолжай интервью с новым вопросом.
    7. Неспрашивай то, что ранее уже сказал ты сам или кандидат.
    8. Твоя цель получать ответы на вопросы, которые помогут оценить технические навыки кандидата.
    9. Если ты считаешь, что интервью можно завершить — аккуратно попрощайся с кандидатом и скажи, что свяжетесь с ним позже. А также если кандидат попросил завершить интервью.
    """
    
    # Мы передаем историю сообщений, чтобы Интервьюер видел, на чем остановился диалог
    response = llm.invoke([
        ("system", prompt),
        *state["messages"]
    ])
    
    return {"messages": [response]}